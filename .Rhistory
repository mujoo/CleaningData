2+2
7:3 -1
7:3
stack.loss
stack.loss/7
help stack.loss
?stack.loss
help("stack.loss")
args(mean)
args(sort)
args(rev)
mean(stack.loss,trim=.20)
sort(stack.loss)
rev(sort(stack.loss))
?mean
objects()
search()
find("mean")
?class
?mode
exit
q
getwd()
debug(ls)
ls
ls
1
set.seed(1)
rpois(5,2)
library(swirl)
swirl()
swirl()
install.packages("swirl")
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
swirl()
swirl()
mydf<-read.csv("path2csv",stringsAsFactors = FALSE)
mydf<-read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head()
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran, ip_id, package, country)
5:20
(cran, r_arch:country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size)
)
select(cran, -time)
select(cran, -(X:size))
filter(cran, package == "swirl")
ilter(cran,
| r_version == "3.1.1", country == "US")
ilter(cran, r_version == "3.1.1", country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparision
?Comparison
filter(cran, r_version <= "3.1.1", country == "India")
filter(cran, r_version <= "3.1.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 , r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran,  !is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country (ascending), r_version(descending),  ip_id (ascending))
arrange(cran2, country, desc(r_version),  ip_id )
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20,size_gb= size_mb / 2^10)
cran3
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package, avg_bytes = mean(size))
summarize(by_package,  mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum,  n()>679)
top_counts<-filter(pack_sum,  count>679)
top_counts
head(top_counts, 20)
arrange(top_counts,  desc(count) )
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum$unique,  count>465)
top_unique<-filter(pack_sum,  count>465)
filter(pack_sum, unique > 465)
top_unique<-filter(pack_sum,  unique>465)
top_unique
arrange(top_unique,  desc(unique) )
submit()
submit()
submit()
swirl()
swirl()
submit()
submit()
submit()
submit()
submit()
submit()
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
res<-gather(students2,sex_class,count,-grade)
res
?seperate
?seperate()
?separate
seperate(res,col=sex_class,into=c(sex",class"))
seperate(data=res,col=sex_class,into=c(sex",class"))
separate(data=res,col=sex_class,into=c(sex",class"))
separate(data=res,col=sex_class,into=c(sex","class"))
separate(data=res,col=sex_class,into=c("sex","class"))
submit()
students3
submit()
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
submit()
submit()
?mutate
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
passed<-mutate(passed, status="passed")
failed<-mutate(failed, status="failed")
?rbind_list
rbind_list(passed,failed)
sat
?gather
submit()
View(result1)
submit()
?select
submit()
submit()
?gather
submit()
submit()
submit()
submit()
?group_by
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package
| = lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label=TRUE)
this_moment<-now()
this_moment
year(this_moment)
hour(this_moment)
my_date<-this_day <- today()
my_date
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
mdy(25081985)
dmy(25081985)
ymd("192012")
ymd("19-20-12")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd_hms(dt2)
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment<-update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
?now
now(tzone="America/New_York)")
nyc<-now(tzone="America/New_York)")
now("America/New_York")
nyc<-now("America/New_York")
nyc
depart<-nyc + days(2)
depart
depart<-update(depart, hours = 17, minutes = 34)
depart
arrive<-nyc + hours(15)+min(50)
arrive<-nyc + hours(15)+minutes(50)
arrive<-depart + hours(15)+minutes(50)
?with_tz
arrive<-with_tz(arrive,tzone="Asia/Hong_Kong")
arrive
last_time<-mdy("June 17, 2008",tz="Singapore")
last_time
?new_interval()
?new_interval
how-long(last_time,arrive)
how-long<-(last_time,arrive)
how-long<-new_interval(last_time,arrive)
how_long<-new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
exit
exit()
0
install.packages("ggplot2")
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
?geom
?qplot
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
?text
?lpoints
?lines
?points
?lpoints
?text
?trellis.par.set
?points
?lines
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
install.packages("reshape2")
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
setwd("~/Rworkingdir/cleaning data/data")
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
source project/run.analysis.R
source ./project/run.analysis.R
source "project/run.analysis.R"
source "./project/run.analysis.R"
source "run.analysis.R"
source "run_analysis.R"
source run_analysis.R
?source
# merge training and test datasets. merge.datasets function returns a list
# merge training and test datasets. merge.datasets function returns a list
source('~/Rworkingdir/cleaning data/data/UCI HAR Dataset/run_analysis.R')
source('~/Rworkingdir/cleaning data/data/UCI HAR Dataset/run_analysis.R')
features <- read.table("./UCI HAR Dataset/features.txt")
# Find the mean and std columns
mean.col <- sapply(features[,2], function(x) grepl("mean()", x, fixed=T))
std.col <- sapply(features[,2], function(x) grepl("std()", x, fixed=T))
# Extract them from the data
exdf <- df[, (mean.col | std.col)]
colnames(exdf) <- features[(mean.col | std.col), 2]
exdf
}
name.activities = function(df) {
# Use descriptive activity names to name the activities in the dataset
colnames(df) <- "activity"
df$activity[df$activity == 1] = "WALKING"
df$activity[df$activity == 2] = "WALKING_UPSTAIRS"
df$activity[df$activity == 3] = "WALKING_DOWNSTAIRS"
df$activity[df$activity == 4] = "SITTING"
df$activity[df$activity == 5] = "STANDING"
df$activity[df$activity == 6] = "LAYING"
df
}
bind.data <- function(x, y, subjects) {
# Combine mean-std values (x), activities (y) and subjects into one data
# frame.
cbind(x, y, subjects)
}
create.tidy.dataset = function(df) {
# Given X values, y values and subjects, create an independent tidy dataset
# with the average of each variable for each activity and each subject.
tidy <- ddply(df, .(subject, activity), function(x) colMeans(x[,1:60]))
tidy
}
clean.data = function() {
# Download data
download.data()
# merge training and test datasets. merge.datasets function returns a list
# of three dataframes: X, y, and subject
merged <- merge.datasets()
# Extract only the measurements of the mean and standard deviation for each
# measurement
cx <- extract.mean.and.std(merged$x)
# Name activities
cy <- name.activities(merged$y)
# Use descriptive column name for subjects
colnames(merged$subject) <- c("subject")
# Combine data frames into one
combined <- bind.data(cx, cy, merged$subject)
# Create tidy dataset
tidy <- create.tidy.dataset(combined)
# Write tidy dataset as csv
write.csv(tidy, "UCI_HAR_tidy.csv", row.names=FALSE)
}
# Load: activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
# Load: data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
# Bind data
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels   = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data      = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = "./tidy_data.txt")
write.table(tidy, "tidy.txt", sep="\t")
source('~/.active-rstudio-document')
trainData_act <- read.table("./UCI HAR Dataset/train/y_train.txt",header=FALSE)
trainData_sub <- read.table("./UCI HAR Dataset/train/subject_train.txt",header=FALSE)
# 3. Uses descriptive activity names to name the activities in the data set
activities <- read.table("./UCI HAR Dataset/activity_labels.txt",header=FALSE,colClasses="character")
testData_act$V1 <- factor(testData_act$V1,levels=activities$V1,labels=activities$V2)
trainData_act$V1 <- factor(trainData_act$V1,levels=activities$V1,labels=activities$V2)
# 4. Appropriately labels the data set with descriptive activity names
features <- read.table("./UCI HAR Dataset/features.txt",header=FALSE,colClasses="character")
colnames(testData)<-features$V2
colnames(trainData)<-features$V2
colnames(testData_act)<-c("Activity")
colnames(trainData_act)<-c("Activity")
colnames(testData_sub)<-c("Subject")
colnames(trainData_sub)<-c("Subject")
# 1. merge test and training sets into one data set, including the activities
testData<-cbind(testData,testData_act)
testData<-cbind(testData,testData_sub)
trainData<-cbind(trainData,trainData_act)
trainData<-cbind(trainData,trainData_sub)
bigData<-rbind(testData,trainData)
# 2. extract only the measurements on the mean and standard deviation for each measurement
bigData_mean<-sapply(bigData,mean,na.rm=TRUE)
bigData_sd<-sapply(bigData,sd,na.rm=TRUE)
# 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
DT <- data.table(bigData)
tidy<-DT[,lapply(.SD,mean),by="Activity,Subject"]
write.table(tidy,file="tidy.csv",sep=",",row.names = FALSE)
clear
library(plyr)
setwd("~/Rworkingdir/cleaning data/data/UCI HAR Dataset")
source('~/Rworkingdir/cleaning data/data/UCI HAR Dataset/run_analysis.R')
write.csv(mergedData, file="all_data.csv", row.names=FALSE)
source('~/.active-rstudio-document')
setwd("~/Rworkingdir/cleaning data/data")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
setwd("~/Rworkingdir/cleaning data/UCI HAR Dataset")
setwd("~/Rworkingdir/cleaning data")
source('~/.active-rstudio-document')
setwd("~/Rworkingdir/cleaning data/Project")
git init
